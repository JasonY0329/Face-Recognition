{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import math\n","!pip install pyheif\n","import pyheif\n","import re\n","\n","!pip install dlib\n","import dlib\n","!pip install face_recognition\n","!pip3 install scikit-learn\n","from sklearn import neighbors\n","import pickle\n","from PIL import Image, ImageDraw, ImageFont\n","import face_recognition\n","from face_recognition.face_recognition_cli import image_files_in_folder\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'PNG', 'JPG', 'JPEG', 'HEIC', 'heic'}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_cYgWTx0uM9","outputId":"6f9cbb5a-8cc4-43f2-c25a-16e8d0844dc9","executionInfo":{"status":"ok","timestamp":1702070770199,"user_tz":480,"elapsed":61590,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyheif\n","  Downloading pyheif-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyheif) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->pyheif) (2.21)\n","Installing collected packages: pyheif\n","Successfully installed pyheif-0.7.1\n","Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n","Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=e236bc8bdf4e1bea98ef34c6769187a919fd58c59f030607e6a3d0760704cc35\n","  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7HGWgwE0uKL","outputId":"6a77c7bc-7996-41e4-fff1-857f7161ef78","executionInfo":{"status":"ok","timestamp":1702070807532,"user_tz":480,"elapsed":37338,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Train the model: a k-nearest neighbors classifier for face recognition\n","# :param path: directory that contains a sub-directory (named as the person name) for each known person.\n","\n","def train(path, n_neighbors=None, knn_algo='ball_tree', verbose=True, test_size=0.3):\n","\n","  # Initiate the train and validate set\n","  X_train, X_val, y_train, y_val = [], [], [], []\n","\n","  # Loop through each person/className in the training set\n","  for class_dir in os.listdir(path):\n","    if not os.path.isdir(os.path.join(path, class_dir)):\n","      continue\n","\n","    encodeListKnown = [] # each image's encoding\n","    classNames = [] # person's name corresponding to the image\n","\n","    # Loop through each training image for the current person\n","    for img_path in image_files_in_folder(os.path.join(path, class_dir)):\n","      # skip the non-image file\n","      if img_path.split(\".\")[-1] not in ALLOWED_EXTENSIONS:\n","        continue\n","\n","      # handle the \".HEIC\" training image\n","      if img_path.split(\".\")[-1] in {'HEIC', 'heic'}:\n","          heif_file = pyheif.read(img_path)\n","          reImg = Image.frombytes(\n","            heif_file.mode,\n","            heif_file.size,\n","            heif_file.data,\n","            \"raw\",\n","            heif_file.mode,\n","            heif_file.stride,\n","          )\n","          image = np.array(reImg)\n","      else: image = face_recognition.load_image_file(img_path)\n","\n","      face_bounding_boxes = face_recognition.face_locations(image)\n","\n","      if len(face_bounding_boxes) != 1:\n","      # If there are no people (or too many people) in a training image, skip the image.\n","        if verbose:\n","            print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n","      else:\n","      # Add face encoding for current image to the training set\n","        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        encode = face_recognition.face_encodings(img, known_face_locations=face_bounding_boxes)[0]\n","        encodeListKnown.append(encode)\n","        classNames.append(class_dir)\n","\n","    if len(encodeListKnown) < 3:\n","      test_size = 0.5\n","\n","    # Split the data into training and validation sets\n","    ppl_X_train, ppl_X_val, ppl_y_train, ppl_y_val = train_test_split(\n","        encodeListKnown, classNames, test_size=test_size, random_state=42\n","    )\n","\n","    # Add the training and val sets for this person to the whole training & val sets.\n","    X_train.extend(ppl_X_train)\n","    X_val.extend(ppl_X_val)\n","    y_train.extend(ppl_y_train)\n","    y_val.extend(ppl_y_val)\n","\n","  # Determine how many neighbors to use for weighting in the KNN classifier\n","  if n_neighbors is None:\n","      n_neighbors = int(round(math.sqrt(len(X_train))))\n","      if verbose:\n","          print(\"Chose n_neighbors automatically:\", n_neighbors)\n","\n","  # Create and train the KNN classifier\n","  knn_clf = neighbors.KNeighborsClassifier(\n","  n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance'\n","  )\n","  knn_clf.fit(X_train, y_train)\n","\n","  # Predictions on the validation set\n","  y_pred = knn_clf.predict(X_val)\n","\n","  # Calculate precision, recall, and F1-score\n","  precision = precision_score(y_val, y_pred, average='weighted')\n","  recall = recall_score(y_val, y_pred, average='weighted')\n","  f1 = f1_score(y_val, y_pred, average='weighted')\n","\n","  print(f\"Precision: {precision:.4f}\")\n","  print(f\"Recall: {recall:.4f}\")\n","  print(f\"F1-score: {f1:.4f}\")\n","\n","  return knn_clf"],"metadata":{"id":"CfklvomG0uHW","executionInfo":{"status":"ok","timestamp":1702070807533,"user_tz":480,"elapsed":6,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Predict the unknown images:\n","# Recognizes faces in given image using a trained KNN classifier\n","\n","def predict(X_img, knn_clf=None, distance_threshold=0.47):\n","\n","  X_face_locations = face_recognition.face_locations(X_img)\n","\n","  # If no faces are found in the image, return an empty result.\n","  if len(X_face_locations) == 0:\n","    # print(\"Didn't find a face in the image.\")\n","    return []\n","\n","  # Find encodings for faces in the test iamge\n","  faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n","\n","  # Use the KNN model to find the best matches for the test face\n","  closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n","  #print(\"Closest distances are:\", closest_distances)\n","\n","  are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n","  #print(\"Match with the object? \", are_matches)\n","\n","  # Predict classes and remove classifications that aren't within the threshold\n","  return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n","\n"],"metadata":{"id":"nucheX0u0uEt","executionInfo":{"status":"ok","timestamp":1702070807533,"user_tz":480,"elapsed":5,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**Main Function**"],"metadata":{"id":"FqmME_pXVIdn"}},{"cell_type":"markdown","source":["Train the model"],"metadata":{"id":"gkR_8mhIVKY1"}},{"cell_type":"code","source":["# TRAIN THE MODEL:\n","# Train the KNN classifier and get the KNN clf for later use.\n","\n","# import the training images from the path\n","trainPath = '/content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train'\n","\n","print(\"Training KNN classifier...\")\n","# call the train function\n","classifier = train(trainPath, n_neighbors=2)\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVkBRGDq0uB4","outputId":"7b99b272-a30f-4bac-f098-b24050da36d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training KNN classifier...\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Anirudh/0921-ClassPhotos .png not suitable for training: Found more than one face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Shreya Devendra/Shreya Bisen (09_28).jpeg not suitable for training: Found more than one face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Kaiyue/d44a505436e430369cba0f59823fd93.png not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Kaiyue/5d597c554c1b04c3276677553f1a3c8.png not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Kaiyue/167f63c69e174e2ff4b596ec38b2b94.png not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Kaiyue/8c573925b8c9b928d818de6265da8c8.png not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Kaiyue/1698095638686.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Varshit/Image 9-23-23 at 12.10 PM.jpeg not suitable for training: Found more than one face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Pooja/IMG_Sep19.jpeg not suitable for training: Found more than one face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Zhiyu/1695316397.687358.jpg not suitable for training: Found more than one face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Zhiyu/1696527526.06545.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Yutong/1696298062.831307.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Yutong/1696544946.764776.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Yutong/1696544875.703294.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Yutong/1697605755.541178.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Yutong/1697767552.7825.jpg not suitable for training: Didn't find a face\n","Image /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/train/Dheeraj/Dheeraj_cropped_09-26_1.jpeg not suitable for training: Found more than one face\n","Precision: 1.0000\n","Recall: 1.0000\n","F1-score: 1.0000\n","Training complete!\n"]}]},{"cell_type":"code","source":["# Save the model for later use\n","\n","with open('/content/drive/My Drive/SCU COEN 240 Machine Learning/trainedModel/knn_model.pkl', 'wb') as f:\n","    pickle.dump(classifier, f)"],"metadata":{"id":"57yYX8AS0t-p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test the model"],"metadata":{"id":"ffS_7z4RVNwl"}},{"cell_type":"code","source":["# Datasets path:\n","\n","# Import the lables text file:\n","labels_path = '/content/drive/MyDrive/SCU COEN 240 Machine Learning/data/test/labels.txt'\n","# Import the testing pictures file:\n","testPath = '/content/drive/MyDrive/SCU COEN 240 Machine Learning/data/test'"],"metadata":{"id":"GVcE8o_T1ATM","executionInfo":{"status":"ok","timestamp":1702070826478,"user_tz":480,"elapsed":147,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Read the text file and extract the second column as true labels\n","\n","labels = []\n","with open(labels_path, 'r') as file:\n","    for line in file:\n","      elements = line.strip().split('\\t')\n","      combined = '-'.join(elements)  # Combine the elements with '-'\n","      labels.append(combined)\n","\n","# sort the label\n","labels = sorted(labels, key=lambda x: int(x.split('_')[0]))\n","true_labels = [label.split('-')[-1] for label in labels]\n","\n","# Display the label list:\n","print(labels)\n","print(len(labels))\n","print(true_labels)\n","print(len(true_labels))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFz3tiBc1AQx","outputId":"fb0af0f2-3494-473f-9135-603b4c09025b","executionInfo":{"status":"ok","timestamp":1702072673778,"user_tz":480,"elapsed":181,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['2_0.jpeg-Anirudh', '3_0.jpeg-Anirudh', '4_0.jpeg-Anirudh', '5_0.jpeg-Anirudh', '7_0.jpeg-Aparnaa', '8_0.jpeg-Aparnaa', '10_0.jpeg-Chen', '11_0.jpeg-Chen', '12_0.jpeg-Chen', '14_0.jpeg-Chen', '16_0.jpeg-Dheeraj', '17_0.jpeg-Dheeraj', '18_0.jpeg-Divyanth', '19_0.jpeg-Divyanth', '20_0.jpeg-Divyanth', '21_0.jpeg-Divyanth', '22_0.jpeg-Griffin', '23_0.jpeg-Griffin', '24_0.jpeg-Griffin', '25_0.jpeg-Griffin', '26_0.jpeg-Haisong', '27_0.jpeg-Haisong', '28_0.jpeg-Haisong', '29_0.jpeg-Haisong', '30_0.jpeg-Haochen', '31_0.jpeg-Haochen', '32_0.jpeg-Haochen', '33_0.jpeg-Haochen', '35_0.jpeg-Huiyu', '37_0.jpeg-Huiyu', '38_0.jpeg-Huiyu', '39_0.jpeg-Huiyu', '40_0.jpeg-Husain', '41_0.jpeg-Husain', '42_0.jpeg-Husain', '44_0.jpeg-Husain', '47_0.jpeg-Kaiyue', '48_1.jpeg-Kaiyue', '49_0.jpeg-Kimsong', '51_0.jpeg-Kimsong', '52_0.jpeg-Kimsong', '53_0.jpeg-Kimsong', '58_0.jpeg-Madhuri', '59_0.jpeg-Madhuri', '60_0.jpeg-Madhuri', '61_0.jpeg-Manya', '62_0.jpeg-Manya', '63_0.jpeg-Manya', '64_0.jpeg-Peiqi', '65_1.jpeg-Peiqi', '66_0.jpeg-Peiqi', '68_0.jpeg-Peiqi', '69_0.jpeg-Pooja', '69_1.jpeg-Pooja', '70_0.jpeg-Pooja', '71_0.jpeg-Pooja', '74_0.jpeg-Prachi', '75_0.jpeg-Prachi', '76_3.jpeg-Qihui', '78_0.jpeg-Qihui', '79_0.jpeg-Qihui', '80_0.jpeg-Qihui', '81_0.jpeg-Ruthu', '82_0.jpeg-Ruthu', '83_0.jpeg-Ruthu', '84_0.jpeg-Samyuktha', '86_0.jpeg-Samyuktha', '87_0.jpeg-Samyuktha', '88_0.jpeg-ShreyaChinthala', '89_0.jpeg-ShreyaChinthala', '90_0.jpeg-ShreyaChinthala', '92_0.jpeg-ShreyaDevendra', '93_0.jpeg-ShreyaDevendra', '94_0.jpeg-ShreyaDevendra', '95_0.jpeg-ShreyaDevendra', '96_0.jpeg-Shreyas', '97_0.jpeg-Shreyas', '98_0.jpeg-Shreyas', '100_0.jpeg-Shreyas', '101_0.jpeg-Shubham', '102_0.jpeg-Shubham', '103_0.jpeg-Shubham', '104_0.jpeg-Shubham', '105_0.jpeg-Varshit', '106_0.jpeg-Varshit', '107_0.jpeg-Varshit', '108_0.jpeg-Varshit', '118_0.jpeg-Wagawaththa', '119_0.jpeg-Wei', '120_0.jpeg-Wei', '122_0.jpeg-Wei', '123_0.jpeg-Wei', '124_0.jpeg-Xinze', '125_1.jpeg-Xinze', '127_0.jpeg-Xinze', '128_1.jpeg-Xinze', '129_0.jpeg-Yash', '130_0.jpeg-Yash', '131_0.jpeg-Yash', '132_0.jpeg-Yash', '134_0.jpeg-Yuhang', '135_0.jpeg-Yuhang', '137_0.jpeg-Yuhang', '138_0.jpeg-Yuhang', '140_0.jpeg-Zexin', '141_0.jpeg-Zexin', '142_0.jpeg-Zexin', '143_0.jpeg-Zexin', '144_0.jpeg-Zhiyu', '145_0.jpeg-Zhiyu', '146_0.jpeg-Zhiyu', '147_0.jpeg-Zhiyu']\n","112\n","['Anirudh', 'Anirudh', 'Anirudh', 'Anirudh', 'Aparnaa', 'Aparnaa', 'Chen', 'Chen', 'Chen', 'Chen', 'Dheeraj', 'Dheeraj', 'Divyanth', 'Divyanth', 'Divyanth', 'Divyanth', 'Griffin', 'Griffin', 'Griffin', 'Griffin', 'Haisong', 'Haisong', 'Haisong', 'Haisong', 'Haochen', 'Haochen', 'Haochen', 'Haochen', 'Huiyu', 'Huiyu', 'Huiyu', 'Huiyu', 'Husain', 'Husain', 'Husain', 'Husain', 'Kaiyue', 'Kaiyue', 'Kimsong', 'Kimsong', 'Kimsong', 'Kimsong', 'Madhuri', 'Madhuri', 'Madhuri', 'Manya', 'Manya', 'Manya', 'Peiqi', 'Peiqi', 'Peiqi', 'Peiqi', 'Pooja', 'Pooja', 'Pooja', 'Pooja', 'Prachi', 'Prachi', 'Qihui', 'Qihui', 'Qihui', 'Qihui', 'Ruthu', 'Ruthu', 'Ruthu', 'Samyuktha', 'Samyuktha', 'Samyuktha', 'ShreyaChinthala', 'ShreyaChinthala', 'ShreyaChinthala', 'ShreyaDevendra', 'ShreyaDevendra', 'ShreyaDevendra', 'ShreyaDevendra', 'Shreyas', 'Shreyas', 'Shreyas', 'Shreyas', 'Shubham', 'Shubham', 'Shubham', 'Shubham', 'Varshit', 'Varshit', 'Varshit', 'Varshit', 'Wagawaththa', 'Wei', 'Wei', 'Wei', 'Wei', 'Xinze', 'Xinze', 'Xinze', 'Xinze', 'Yash', 'Yash', 'Yash', 'Yash', 'Yuhang', 'Yuhang', 'Yuhang', 'Yuhang', 'Zexin', 'Zexin', 'Zexin', 'Zexin', 'Zhiyu', 'Zhiyu', 'Zhiyu', 'Zhiyu']\n","112\n"]}]},{"cell_type":"code","source":["# TEST THE MODEL:\n","# Using the trained classifier, make predictions for unknown images\n","\n","# Load the saved model\n","\n","with open('/content/drive/My Drive/SCU COEN 240 Machine Learning/trainedModel/knn_model.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","\n","if __name__ == \"__main__\":\n","    predictList = []\n","\n","    for image_file in os.listdir(testPath):\n","        full_file_path = os.path.join(testPath, image_file)\n","\n","        if not os.path.isfile(full_file_path) or os.path.splitext(full_file_path)[1][1:] not in ALLOWED_EXTENSIONS:\n","            print(\"This is the label path: {}\".format(full_file_path))\n","            continue\n","\n","        if image_file.split(\".\")[-1] in {'HEIC', 'heic'}:\n","            heif_file = pyheif.read(full_file_path)\n","            reImg = Image.frombytes(\n","                heif_file.mode,\n","                heif_file.size,\n","                heif_file.data,\n","                \"raw\",\n","                heif_file.mode,\n","                heif_file.stride,\n","            )\n","            X_img = np.array(reImg)\n","        else:\n","            X_img = face_recognition.load_image_file(full_file_path)\n","\n","        predictions = predict(X_img, knn_clf=model)\n","        if len(predictions) == 0:\n","            print(\"Didn't find a face in the image: {}\".format(image_file))\n","            predictName = (\"-\").join([image_file, \"Unknown\"])\n","            predictList.append(predictName)\n","            continue\n","\n","\n","        for name, (top, right, bottom, left) in predictions:\n","            predictName = (\"-\").join([image_file, name])\n","            predictList.append(predictName)\n","\n","    predictList = sorted(predictList, key=lambda x: int(x.split('_')[0]))\n","    predictNameList = [pre.split(\"-\")[-1] for pre in predictList]\n","    print(\"Predict List:\", predictList)\n","    print(\"Predict name:\", predictNameList)\n","\n","    precision = precision_score(true_labels, predictNameList, average='weighted')\n","    recall = recall_score(true_labels, predictNameList, average='weighted')\n","    f1 = f1_score(true_labels, predictNameList, average='weighted')\n","\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1-score: {f1:.4f}\")\n","    print(\" \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-QNq-RB1ANx","outputId":"c86132ab-2d42-4b66-b1e5-9a0f50cc39e7","executionInfo":{"status":"ok","timestamp":1702072537881,"user_tz":480,"elapsed":7255,"user":{"displayName":"Cassie Mo","userId":"10199849668335921267"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["This is the label path: /content/drive/MyDrive/SCU COEN 240 Machine Learning/data/test/labels.txt\n","Predict List: ['2_0.jpeg-Anirudh', '3_0.jpeg-Anirudh', '4_0.jpeg-Anirudh', '5_0.jpeg-Anirudh', '7_0.jpeg-Aparnaa', '8_0.jpeg-Aparnaa', '10_0.jpeg-Chen', '11_0.jpeg-Chen', '12_0.jpeg-Chen', '14_0.jpeg-Chen', '16_0.jpeg-Dheeraj', '17_0.jpeg-Dheeraj', '18_0.jpeg-Divyanth', '19_0.jpeg-Divyanth', '20_0.jpeg-Divyanth', '21_0.jpeg-Divyanth', '22_0.jpeg-Griffin', '23_0.jpeg-Griffin', '24_0.jpeg-Griffin', '25_0.jpeg-Griffin', '26_0.jpeg-Haisong', '27_0.jpeg-Haisong', '28_0.jpeg-Haisong', '29_0.jpeg-Haisong', '30_0.jpeg-Haochen', '31_0.jpeg-Haochen', '32_0.jpeg-Haochen', '33_0.jpeg-Haochen', '35_0.jpeg-Huiyu', '37_0.jpeg-Huiyu', '38_0.jpeg-Huiyu', '39_0.jpeg-Huiyu', '40_0.jpeg-Husain', '41_0.jpeg-Husain', '42_0.jpeg-Husain', '44_0.jpeg-Husain', '47_0.jpeg-Kaiyue', '48_1.jpeg-Kaiyue', '49_0.jpeg-Kimsong', '51_0.jpeg-Kimsong', '52_0.jpeg-Kimsong', '53_0.jpeg-Kimsong', '58_0.jpeg-Madhuri', '59_0.jpeg-Madhuri', '60_0.jpeg-Madhuri', '61_0.jpeg-Manya', '62_0.jpeg-Manya', '63_0.jpeg-Manya', '64_0.jpeg-Peiqi', '65_1.jpeg-Peiqi', '66_0.jpeg-Peiqi', '68_0.jpeg-Peiqi', '69_0.jpeg-Pooja', '69_1.jpeg-Pooja', '70_0.jpeg-Pooja', '71_0.jpeg-Pooja', '74_0.jpeg-Prachi', '75_0.jpeg-Prachi', '76_3.jpeg-Qihui', '78_0.jpeg-Qihui', '79_0.jpeg-Qihui', '80_0.jpeg-Qihui', '81_0.jpeg-Ruthu', '82_0.jpeg-Ruthu', '83_0.jpeg-Ruthu', '84_0.jpeg-Samyuktha', '86_0.jpeg-Samyuktha', '87_0.jpeg-Samyuktha', '88_0.jpeg-ShreyaChinthala', '89_0.jpeg-ShreyaChinthala', '90_0.jpeg-ShreyaChinthala', '92_0.jpeg-ShreyaDevendra', '93_0.jpeg-ShreyaDevendra', '94_0.jpeg-ShreyaDevendra', '95_0.jpeg-ShreyaDevendra', '96_0.jpeg-Shreyas', '97_0.jpeg-Shreyas', '98_0.jpeg-Shreyas', '100_0.jpeg-Shreyas', '101_0.jpeg-Shubham', '102_0.jpeg-Shubham', '103_0.jpeg-Shubham', '104_0.jpeg-Shubham', '105_0.jpeg-Varshit', '106_0.jpeg-Varshit', '107_0.jpeg-Varshit', '108_0.jpeg-Varshit', '118_0.jpeg-Wagawaththa', '119_0.jpeg-Wei', '120_0.jpeg-Wei', '122_0.jpeg-Wei', '123_0.jpeg-Wei', '124_0.jpeg-Xinze', '125_1.jpeg-Xinze', '127_0.jpeg-Xinze', '128_1.jpeg-Xinze', '129_0.jpeg-Yash', '130_0.jpeg-Yash', '131_0.jpeg-Yash', '132_0.jpeg-Yash', '134_0.jpeg-Yuhang', '135_0.jpeg-Yuhang', '137_0.jpeg-Yuhang', '138_0.jpeg-Yuhang', '140_0.jpeg-Zexin', '141_0.jpeg-Zexin', '142_0.jpeg-Zexin', '143_0.jpeg-Zexin', '144_0.jpeg-Zhiyu', '145_0.jpeg-Zhiyu', '146_0.jpeg-Zhiyu', '147_0.jpeg-Zhiyu']\n","Predict name: ['Anirudh', 'Anirudh', 'Anirudh', 'Anirudh', 'Aparnaa', 'Aparnaa', 'Chen', 'Chen', 'Chen', 'Chen', 'Dheeraj', 'Dheeraj', 'Divyanth', 'Divyanth', 'Divyanth', 'Divyanth', 'Griffin', 'Griffin', 'Griffin', 'Griffin', 'Haisong', 'Haisong', 'Haisong', 'Haisong', 'Haochen', 'Haochen', 'Haochen', 'Haochen', 'Huiyu', 'Huiyu', 'Huiyu', 'Huiyu', 'Husain', 'Husain', 'Husain', 'Husain', 'Kaiyue', 'Kaiyue', 'Kimsong', 'Kimsong', 'Kimsong', 'Kimsong', 'Madhuri', 'Madhuri', 'Madhuri', 'Manya', 'Manya', 'Manya', 'Peiqi', 'Peiqi', 'Peiqi', 'Peiqi', 'Pooja', 'Pooja', 'Pooja', 'Pooja', 'Prachi', 'Prachi', 'Qihui', 'Qihui', 'Qihui', 'Qihui', 'Ruthu', 'Ruthu', 'Ruthu', 'Samyuktha', 'Samyuktha', 'Samyuktha', 'ShreyaChinthala', 'ShreyaChinthala', 'ShreyaChinthala', 'ShreyaDevendra', 'ShreyaDevendra', 'ShreyaDevendra', 'ShreyaDevendra', 'Shreyas', 'Shreyas', 'Shreyas', 'Shreyas', 'Shubham', 'Shubham', 'Shubham', 'Shubham', 'Varshit', 'Varshit', 'Varshit', 'Varshit', 'Wagawaththa', 'Wei', 'Wei', 'Wei', 'Wei', 'Xinze', 'Xinze', 'Xinze', 'Xinze', 'Yash', 'Yash', 'Yash', 'Yash', 'Yuhang', 'Yuhang', 'Yuhang', 'Yuhang', 'Zexin', 'Zexin', 'Zexin', 'Zexin', 'Zhiyu', 'Zhiyu', 'Zhiyu', 'Zhiyu']\n","Precision: 1.0000\n","Recall: 1.0000\n","F1-score: 1.0000\n"," \n"]}]}]}